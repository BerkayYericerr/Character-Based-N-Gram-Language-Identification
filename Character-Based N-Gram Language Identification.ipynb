{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh3Qjh8mRHqD"
      },
      "source": [
        "# Assignment 2: N-grams and Language Identification\n",
        "## CNG463 - Introduction to Natural Language Processing\n",
        "### METU NCC Computer Engineering | Fall 2025-26\n",
        "\n",
        "**Student Name:**Berkay Yeriçer\n",
        "**Student ID:**238572\n",
        "**Due Date:** 16 November 2025 (Sunday) before midnight\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyDEnwcxRHqE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This assignment focuses on:\n",
        "1. Building **character-based** 2-gram and 3-gram language models with Laplace smoothing\n",
        "2. Sentence-based language identification using 10-fold cross-validation\n",
        "3. Evaluation using accuracy, precision, recall, and F1-score\n",
        "4. Comparison and analysis\n",
        "\n",
        "**Note:** For language identification, we use **character n-grams** rather than word n-grams because they better capture language-specific patterns like letter combinations, diacritics, and writing systems.\n",
        "\n",
        "**Grading:**\n",
        "- Written Questions (7 × 4 pts): **28 pts**\n",
        "- Code Tasks with TODO (11 total): **72 pts** distributed by effort level:\n",
        "  - Simple tasks: 4 pts each (2 cells)\n",
        "  - Moderate tasks: 6 pts each (4 cells)\n",
        "  - Complex tasks: 8 pts each (5 cells)\n",
        "- **Total: 100 pts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srF42PZXRHqP"
      },
      "source": [
        "---\n",
        "\n",
        "## Pre-Submission Checklist\n",
        "\n",
        "- [ ] Name and student ID at top\n",
        "- [ ] No cells are added or removed\n",
        "- [ ] All TODO sections completed\n",
        "- [ ] All questions answered\n",
        "- [ ] Code runs without errors\n",
        "- [ ] Results tables included\n",
        "- [ ] Run All before saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq0Xw3YQRHqE"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwyLNfKaRHqE"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Tuple, Dict\n",
        "import re\n",
        "\n",
        "\n",
        "# Scikit-learn for cross-validation and metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr-UNnAGRHqF"
      },
      "source": [
        "---\n",
        "\n",
        "# Task 1: Corpus Preparation and Statistics (22 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5k13c4MRHqF"
      },
      "source": [
        "## 1.1: Upload Corpus Files\n",
        "\n",
        "Prepare your text files in **two different languages** (accepted formats: `.txt`, `.pdf`, or `.docx`). When you run the cell below, you'll be prompted to upload files for each language separately. Make sure your files contain substantial text (reports, essays, or similar content from other courses). Each language requires at least **5000** words in its corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "cb6tjNLmRHqF",
        "outputId": "ddbfabc2-bfd3-4e67-b7bc-0d15adfb869c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your ENGLISH corpus file(s):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1f5cf3d-afea-4400-b1b7-cb059f51985d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1f5cf3d-afea-4400-b1b7-cb059f51985d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Alice’s Adventures in Wonderland – Lewis Carroll.txt to Alice’s Adventures in Wonderland – Lewis Carroll (2).txt\n",
            "\n",
            "Upload your SECOND LANGUAGE corpus file(s):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ca6f7a7-0ccd-4928-9a14-6796cc505a4e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ca6f7a7-0ccd-4928-9a14-6796cc505a4e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Arif Kaptan - Giyotinli Labirent_djvu.txt to Arif Kaptan - Giyotinli Labirent_djvu (2).txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Upload your ENGLISH corpus file(s):\")\n",
        "english_files = files.upload()\n",
        "\n",
        "print(\"\\nUpload your SECOND LANGUAGE corpus file(s):\")\n",
        "second_lang_files = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwDDP9gORHqF"
      },
      "source": [
        "## 1.2: Load and Preprocess Data (12 points)\n",
        "\n",
        "Load your uploaded files, extract text, preprocess, split into sentences, and tokenize. You'll need helper functions to handle different file formats.\n",
        "\n",
        "**Steps:**\n",
        "1. Read files based on format (`.txt`, `.pdf`, `.docx`) and combine them into single text for each language\n",
        "2. Apply preprocessing (e.g., lowercasing, handling punctuation)\n",
        "3. Split each corpus into individual sentences\n",
        "4. Tokenize each sentence into words (for statistics)\n",
        "5. Store the results as two lists of tokenized sentences\n",
        "\n",
        "**Important:** You'll use word tokenization for calculating statistics, but for the n-gram models in Task 2, you'll work with character n-grams directly on the sentence strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI_9lAXTRHqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8f0a55-b60c-4cc3-e495-df58c99756cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "[Lang1] #Sentences: 916 | #tokenized sentences: 916\n",
            "[Lang1] #tokens: 33304 | #types: 2509\n",
            "[Lang2] #Sentences: 2434 | #tokenized sentences: 2434\n",
            "[Lang2] #tokens: 29548 | #types: 9751\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install python-docx\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "from typing import List, Iterable\n",
        "import PyPDF2\n",
        "import docx\n",
        "\n",
        "\n",
        "def read_txt_file(filename: str) -> str:\n",
        "    \"\"\"Read a .txt file and return its content.\"\"\"\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "def read_pdf_file(filename: str) -> str:\n",
        "    \"\"\"Read a .pdf file and return its text content.\"\"\"\n",
        "    text = \"\"\n",
        "    with open(filename, \"rb\") as f:\n",
        "        pdf_reader = PyPDF2.PdfReader(f)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text is not None:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_any_file(filename: str) -> str:\n",
        "    \"\"\"Read .txt, .pdf or .docx file depending on extension.\"\"\"\n",
        "    _, ext = os.path.splitext(filename)\n",
        "    ext = ext.lower()\n",
        "\n",
        "    if ext == \".txt\":\n",
        "        return read_txt_file(filename)\n",
        "    elif ext == \".pdf\":\n",
        "        return read_pdf_file(filename)\n",
        "    elif ext == \".docx\":\n",
        "        return read_docx_file(filename)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type: \" + ext)\n",
        "\n",
        "\n",
        "def read_docx_file(filename: str) -> str:\n",
        "    \"\"\"Read a .docx file and return its text content.\"\"\"\n",
        "    text = \"\"\n",
        "    doc = docx.Document(filename)\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def text_normalizer(text:str, lower:bool=False)->str:\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = text.strip()\n",
        "    if lower:\n",
        "        text = text.lower()\n",
        "    return text\n",
        "\n",
        "def split_into_sentences(text: str) -> List[str]:\n",
        "    \"\"\"Split text into sentences.\"\"\"\n",
        "    pattern = r'(?<=[.!?])\\s+'\n",
        "    pieces = re.split(pattern, text)\n",
        "    sentences: List[str] = []\n",
        "    for s in pieces:\n",
        "        if s is not None:\n",
        "            s = s.strip()\n",
        "            if s != \"\":\n",
        "                sentences.append(s)\n",
        "    return sentences\n",
        "\n",
        "TOKEN_RE = re.compile(\n",
        "    r\"[A-Za-zÇĞİÖŞÜçğıöşü0-9']+|[^\\w\\s]\",\n",
        "    flags=re.UNICODE\n",
        ")\n",
        "\n",
        "def tokenize_sentence(sentence: str) -> List[str]:\n",
        "    \"\"\"Tokenize a sentence into words.\"\"\"\n",
        "    sentence = sentence.lower()\n",
        "    tokens = TOKEN_RE.findall(sentence)\n",
        "    clean_tokens: List[str] = []\n",
        "    for t in tokens:\n",
        "        if t is not None and t.strip() != \"\":\n",
        "            clean_tokens.append(t)\n",
        "\n",
        "    return clean_tokens\n",
        "\n",
        "def combine_files(files: Iterable[str])->str:\n",
        "    all_text = \"\"\n",
        "    for fp in files:\n",
        "        file_text = read_any_file(fp)\n",
        "        all_text += file_text + \"\\n\"\n",
        "    return all_text\n",
        "\n",
        "def corpus_to_sentences_and_tokens(files:Iterable[str]):\n",
        "    if not files:\n",
        "          return [], []\n",
        "\n",
        "    raw_text = combine_files(files)\n",
        "    raw_text = text_normalizer(raw_text, lower=False)\n",
        "    sentences_raw = split_into_sentences(raw_text)\n",
        "    sentences_tok: List[List[str]] = []\n",
        "    for s in sentences_raw:\n",
        "        tokens = tokenize_sentence(s)\n",
        "        sentences_tok.append(tokens)\n",
        "    return sentences_raw, sentences_tok\n",
        "\n",
        "lang1_files = [\n",
        "    \"/content/Alice’s Adventures in Wonderland – Lewis Carroll.txt\"\n",
        "]\n",
        "\n",
        "lang2_files = [\n",
        "    \"/content/Arif Kaptan - Giyotinli Labirent_djvu.txt\"\n",
        "]\n",
        "\n",
        "if lang1_files:\n",
        "    lang1_sentences, lang1_sentences_tokenized = corpus_to_sentences_and_tokens(lang1_files)\n",
        "else:\n",
        "    lang1_sentences, lang1_sentences_tokenized = [], []\n",
        "\n",
        "if lang2_files:\n",
        "    lang2_sentences, lang2_sentences_tokenized = corpus_to_sentences_and_tokens(lang2_files)\n",
        "else:\n",
        "    lang2_sentences, lang2_sentences_tokenized = [], []\n",
        "\n",
        "\n",
        "print(\"[Lang1] #Sentences:\", len(lang1_sentences),\n",
        "      \"| #tokenized sentences:\", len(lang1_sentences_tokenized))\n",
        "\n",
        "if lang1_sentences_tokenized:\n",
        "    total_tokens_l1 = 0\n",
        "    vocab_l1 = set()\n",
        "\n",
        "    for sent in lang1_sentences_tokenized:\n",
        "        total_tokens_l1 += len(sent)\n",
        "        for tok in sent:\n",
        "            vocab_l1.add(tok)\n",
        "\n",
        "    print(\"[Lang1] #tokens:\", total_tokens_l1,\n",
        "          \"| #types:\", len(vocab_l1))\n",
        "\n",
        "\n",
        "print(\"[Lang2] #Sentences:\", len(lang2_sentences),\n",
        "      \"| #tokenized sentences:\", len(lang2_sentences_tokenized))\n",
        "\n",
        "if lang2_sentences_tokenized:\n",
        "    total_tokens_l2 = 0\n",
        "    vocab_l2 = set()\n",
        "\n",
        "    for sent in lang2_sentences_tokenized:\n",
        "        total_tokens_l2 += len(sent)\n",
        "        for tok in sent:\n",
        "            vocab_l2.add(tok)\n",
        "\n",
        "    print(\"[Lang2] #tokens:\", total_tokens_l2,\n",
        "          \"| #types:\", len(vocab_l2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg18ezdTRHqG"
      },
      "source": [
        "**Question 1.1:** What preprocessing choices did you make and why? (3-5 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLjQTbejRHqG"
      },
      "source": [
        "**Hocam first of all I implemented basic file readers.After that the most important thing is normalizing the text. So i normalized by collapsing multiple spaces into one space and trimming extra whitespace, i did this steps because it is important for sentence splitting and tokenization. After that for segmentation i used basic regular expression(actually i tried to use more complex versions but it didnt work ,I dont know why, so i keep them as a basic expressions.)For tokenization i dont want to use the library tokenization, i just want to try in a different way, so i used lightweight regex  tokenizer for kepps words, numbers and punctutions as seperate tokens, because it is important for keeping statistics.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prIqhFYyRHqG"
      },
      "source": [
        "## 1.3: Basic Statistics (10 points)\n",
        "\n",
        "Calculate and display key statistics for both language corpora to understand their characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvSoUoATRHqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea02b21d-58c7-4182-9d19-29b9bfd2b9fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "****** English Corpus Statistics *****\n",
            "Total characters: 133385\n",
            "Special characters: 7969\n",
            "Character vocabulary size: 75\n",
            "Total words: 33304\n",
            "Word vocabulary size: 2509\n",
            "Sentence count: 916\n",
            "Average sentence length (words): 36.36\n",
            "\n",
            "****** Turkish Corpus Statistics *****\n",
            "Total characters: 180266\n",
            "Special characters: 5457\n",
            "Character vocabulary size: 87\n",
            "Total words: 29548\n",
            "Word vocabulary size: 9751\n",
            "Sentence count: 2434\n",
            "Average sentence length (words): 12.14\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "def simple_corpus_stats(sentences, tokenized_sentences, lang_name=\"\"):\n",
        "    \"\"\"Compute basic corpus statistics in a simple and readable way.\"\"\"\n",
        "\n",
        "    # These for total character count\n",
        "    total_chars = 0\n",
        "    for sent in sentences:\n",
        "        total_chars += len(sent)\n",
        "\n",
        "    # These for special character count\n",
        "    special_chars = 0\n",
        "    for sent in sentences:\n",
        "        for ch in sent:\n",
        "            if not ch.isalnum() and not ch.isspace():\n",
        "                special_chars += 1\n",
        "\n",
        "    # These for Character vocabulary size\n",
        "    char_vocab = set()\n",
        "    for sent in sentences:\n",
        "        for ch in sent:\n",
        "            char_vocab.add(ch)\n",
        "    char_vocab_size = len(char_vocab)\n",
        "\n",
        "    # These for total word count\n",
        "    total_words = 0\n",
        "    for sent in tokenized_sentences:\n",
        "        total_words += len(sent)\n",
        "\n",
        "    # These for word vocabulary size\n",
        "    word_vocab = set()\n",
        "    for sent in tokenized_sentences:\n",
        "        for tok in sent:\n",
        "            word_vocab.add(tok)\n",
        "    word_vocab_size = len(word_vocab)\n",
        "\n",
        "    # These for sentence count\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    # These for average sentence length\n",
        "    if num_sentences > 0:\n",
        "        avg_sentence_len = total_words / num_sentences\n",
        "    else:\n",
        "        avg_sentence_len = 0\n",
        "\n",
        "    print(\"\\n****** {} Corpus Statistics *****\".format(lang_name))\n",
        "    print(\"Total characters:\", total_chars)\n",
        "    print(\"Special characters:\", special_chars)\n",
        "    print(\"Character vocabulary size:\", char_vocab_size)\n",
        "    print(\"Total words:\", total_words)\n",
        "    print(\"Word vocabulary size:\", word_vocab_size)\n",
        "    print(\"Sentence count:\", num_sentences)\n",
        "    print(\"Average sentence length (words):\", round(avg_sentence_len, 2))\n",
        "\n",
        "    # return a dictionary if needed later\n",
        "    return {\n",
        "        \"total_chars\": total_chars,\n",
        "        \"special_chars\": special_chars,\n",
        "        \"char_vocab_size\": char_vocab_size,\n",
        "        \"total_words\": total_words,\n",
        "        \"word_vocab_size\": word_vocab_size,\n",
        "        \"num_sentences\": num_sentences,\n",
        "        \"avg_sentence_len\": avg_sentence_len\n",
        "    }\n",
        "\n",
        "stats_en = simple_corpus_stats(lang1_sentences, lang1_sentences_tokenized, \"English\")\n",
        "stats_tr = simple_corpus_stats(lang2_sentences, lang2_sentences_tokenized, \"Turkish\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-PSkjPGRHqG"
      },
      "source": [
        "**Question 1.2:** What are the key differences between your two corpora? (2-3 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS9Y_nWwRHqG"
      },
      "source": [
        "**My opinion is there are two different key factors, the fırst one is book genre.Alice’s Adventures in Wonderland`s genre is childrens book so  we can say that the sentences are more fairytale-like and longer it is triple times longer than \"Giyotinli labirent\".According to this we can see the resultssome statistics. for example due to the long sentences,Alice's sentence count is triple times smaller than giyotili rehber. The second key factor is Languages are different. English texts contains more punctuation, reflecting different writing and stylistic conversation But turkish language has many unique word types due to morphology,like larger vocabulary even with fewer total tokens.In final we can say two different key factor we have, these are book genres and Language difference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMnhFykGRHqG"
      },
      "source": [
        "---\n",
        "\n",
        "# Task 2: Character N-gram Language Identification (58 points)\n",
        "\n",
        "**Baseline (46 pts):** Implement character-based 2-gram and 3-gram models, run 10-fold CV, report accuracy.  \n",
        "**Creativity (12 pts):** Out-of-vocabulary analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugQ7EB70RHqG"
      },
      "source": [
        "## 2.1: Implement Character N-gram Models (12 points)\n",
        "\n",
        "Implement the `CharNgramLanguageModel` class with Laplace smoothing using NLTK's n-gram utilities. The model should count **character** n-grams during training and calculate sentence probabilities with smoothing.\n",
        "\n",
        "**Key difference from word n-grams:** Instead of tokenizing sentences into words, you'll work with individual characters in each sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKiKoqstRHqG"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "class CharNgramLanguageModel:\n",
        "    \"\"\"\n",
        "    Character-based N-gram language model with Laplace (add-1) smoothing using NLTK.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n: int = 2):\n",
        "        \"\"\"\n",
        "        Initialize the character n-gram model.\n",
        "\n",
        "        Args:\n",
        "            n: Order of n-gram (2 for bigram, 3 for trigram)\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.model = Laplace(n)\n",
        "\n",
        "    def train(self, sentences: List[str]):\n",
        "        \"\"\"\n",
        "        Train the model on a list of sentences.\n",
        "\n",
        "        Args:\n",
        "            sentences: List of sentences (each sentence is a string)\n",
        "        \"\"\"\n",
        "        char_sentences = []\n",
        "        for s in sentences:\n",
        "            chars = []\n",
        "            for ch in s.lower(): # lower() so everything is consistent together\n",
        "                chars.append(ch)\n",
        "            char_sentences.append(chars)\n",
        "\n",
        "        # nltk helper that adds padding and converts to n-grams\n",
        "        train_data, vocab = padded_everygram_pipeline(self.n, char_sentences)\n",
        "\n",
        "        # actually training the model\n",
        "        self.model.fit(train_data, vocab)\n",
        "\n",
        "\n",
        "    def get_probability(self, sentence: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculate the probability of a sentence.\n",
        "\n",
        "        Args:\n",
        "            sentence: Sentence string\n",
        "\n",
        "        Returns:\n",
        "            Probability of the sentence\n",
        "        \"\"\"\n",
        "        # converting to character list as we did previously\n",
        "        chars = []\n",
        "        for ch in sentence.lower():\n",
        "            chars.append(ch)\n",
        "\n",
        "        # pad so the model can look at start/end tokens\n",
        "        padded_chars = list(pad_both_ends(chars, n=self.n))\n",
        "        # geting all the n-grams for testing\n",
        "        test_ngrams = list(ngrams(padded_chars, self.n))\n",
        "\n",
        "        # sum of log probs as we talked in the course because they are so small\n",
        "        log_prob = 0.0\n",
        "        for ng in test_ngrams:\n",
        "            context = ng[:-1]   # previous chars\n",
        "            target = ng[-1]     # current chars\n",
        "            p = self.model.score(target, context)\n",
        "            log_prob += math.log(p)\n",
        "\n",
        "        return math.exp(log_prob)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwxpPMNwRHqG"
      },
      "source": [
        "### Spot Check: Inspect Your N-gram Models\n",
        "\n",
        "After implementing the model, train sample models on both languages and inspect what they learned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT9Q6WH8RHqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6314a064-64c9-485b-cf89-e3d8fef709a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Training Models for Spot Check -----\n",
            "\n",
            "----- 2-gram Models -----\n",
            "Language 1 (English) Character Vocabulary Size: 52\n",
            "Top 3 n-grams:\n",
            "   ('e', ' ') : 4439\n",
            "   (' ', 't') : 3889\n",
            "   ('h', 'e') : 3499\n",
            "\n",
            "Language 2 (Turkish) Character Vocabulary Size: 61\n",
            "Top 3 n-grams:\n",
            "   ('n', ' ') : 3283\n",
            "   (' ', 'b') : 3046\n",
            "   ('a', ' ') : 3037\n",
            "\n",
            "----- 3-gram Models -----\n",
            "Language 1 (English) Character Vocabulary Size: 52\n",
            "Top 3 n-grams:\n",
            "   (' ', 't', 'h') : 2497\n",
            "   ('t', 'h', 'e') : 2133\n",
            "   ('h', 'e', ' ') : 2117\n",
            "\n",
            "Language 2 (Turkish) Character Vocabulary Size: 61\n",
            "Top 3 n-grams:\n",
            "   ('.', '</s>', '</s>') : 2326\n",
            "   (' ', 'b', 'i') : 1298\n",
            "   ('b', 'i', 'r') : 1213\n",
            "\n",
            "----- Model Inspection-----\n",
            "Sentence: 'alice was beginning to get very tired'\n",
            "Language 1 (English) Log-Probability: -94.71\n",
            "Language 2 (Turkish) Log-Probability: -130.17\n",
            "Prediction: Language 1 (English)\n",
            "\n",
            "Sentence: 'bugün derste deprem oldu'\n",
            "Language 1 (English) Log-Probability: -82.49\n",
            "Language 2 (Turkish) Log-Probability: -70.35\n",
            "Prediction: Language 2 (Turkish)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(\"----- Training Models for Spot Check -----\")\n",
        "\n",
        "# train 2-gram\n",
        "en2 = CharNgramLanguageModel(n=2)\n",
        "tr2 = CharNgramLanguageModel(n=2)\n",
        "en2.train(lang1_sentences)\n",
        "tr2.train(lang2_sentences)\n",
        "\n",
        "# train 3-gram\n",
        "en3 = CharNgramLanguageModel(n=3)\n",
        "tr3 = CharNgramLanguageModel(n=3)\n",
        "en3.train(lang1_sentences)\n",
        "tr3.train(lang2_sentences)\n",
        "\n",
        "def get_top3(model):\n",
        "    \"\"\"returns top 3 ngrams + counts\"\"\"\n",
        "    n = model.n\n",
        "    c = model.model.counts[n]\n",
        "    all_counts = Counter()\n",
        "\n",
        "    # going through every context and token and counting them\n",
        "    for abc in c:\n",
        "        for tok, val in c[abc].items():\n",
        "            all_counts[abc + (tok,)] += val\n",
        "\n",
        "    return all_counts.most_common(3)\n",
        "\n",
        "def print_top3(model):\n",
        "    top3 = get_top3(model)\n",
        "    for ng, c in top3:\n",
        "        print(\"  \", ng, \":\", c)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Character Vocabulary Info\n",
        "# -----------------------\n",
        "print(\"\\n----- 2-gram Models -----\")\n",
        "print(\"Language 1 (English) Character Vocabulary Size:\", len(en2.model.vocab))\n",
        "print(\"Top 3 n-grams:\")\n",
        "print_top3(en2)\n",
        "\n",
        "print(\"\\nLanguage 2 (Turkish) Character Vocabulary Size:\", len(tr2.model.vocab))\n",
        "print(\"Top 3 n-grams:\")\n",
        "print_top3(tr2)\n",
        "\n",
        "print(\"\\n----- 3-gram Models -----\")\n",
        "print(\"Language 1 (English) Character Vocabulary Size:\", len(en3.model.vocab))\n",
        "print(\"Top 3 n-grams:\")\n",
        "print_top3(en3)\n",
        "\n",
        "print(\"\\nLanguage 2 (Turkish) Character Vocabulary Size:\", len(tr3.model.vocab))\n",
        "print(\"Top 3 n-grams:\")\n",
        "print_top3(tr3)\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Model Inspection\n",
        "# -----------------------\n",
        "print(\"\\n----- Model Inspection-----\")\n",
        "\n",
        "# english test sentence\n",
        "s_en = \"alice was beginning to get very tired\"\n",
        "prob_en_e2 = math.log(en2.get_probability(s_en))\n",
        "prob_en_t2 = math.log(tr2.get_probability(s_en))\n",
        "\n",
        "print(f\"Sentence: '{s_en}'\")\n",
        "print(f\"Language 1 (English) Log-Probability: {prob_en_e2:.2f}\")\n",
        "print(f\"Language 2 (Turkish) Log-Probability: {prob_en_t2:.2f}\")\n",
        "pred_en = \"Language 1 (English)\" if prob_en_e2 > prob_en_t2 else \"Language 2 (Turkish)\"\n",
        "print(\"Prediction:\", pred_en)\n",
        "\n",
        "\n",
        "# turkish test sentence\n",
        "s_tr = \"bugün derste deprem oldu\"\n",
        "prob_tr_e2 = math.log(en2.get_probability(s_tr))\n",
        "prob_tr_t2 = math.log(tr2.get_probability(s_tr))\n",
        "\n",
        "print(f\"\\nSentence: '{s_tr}'\")\n",
        "print(f\"Language 1 (English) Log-Probability: {prob_tr_e2:.2f}\")\n",
        "print(f\"Language 2 (Turkish) Log-Probability: {prob_tr_t2:.2f}\")\n",
        "pred_tr = \"Language 1 (English)\" if prob_tr_e2 > prob_tr_t2 else \"Language 2 (Turkish)\"\n",
        "print(\"Prediction:\", pred_tr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olw1RKdrRHqG"
      },
      "source": [
        "## 2.2: Implement Language Identification (8 points)\n",
        "\n",
        "Create a function that compares sentence probabilities from two language models and returns the predicted label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygVJnY5gRHqG"
      },
      "outputs": [],
      "source": [
        "def identify_language(sentence: str,\n",
        "                     model_lang1: CharNgramLanguageModel,\n",
        "                     model_lang2: CharNgramLanguageModel) -> int:\n",
        "    \"\"\"\n",
        "    Identify the language of a sentence using two character-based language models.\n",
        "\n",
        "    Args:\n",
        "        sentence: Sentence string\n",
        "        model_lang1: Language model for language 1 (label 0)\n",
        "        model_lang2: Language model for language 2 (label 1)\n",
        "\n",
        "    Returns:\n",
        "        Predicted label (0 or 1)\n",
        "    \"\"\"\n",
        "\n",
        "    probabilty_of_1 = model_lang1.get_probability(sentence)\n",
        "    probabilty_of_2 = model_lang2.get_probability(sentence)\n",
        "\n",
        "    if probabilty_of_1 > probabilty_of_2:\n",
        "        return 0   # language 1\n",
        "    else:\n",
        "        return 1   # language 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v9cJXjQRHqG"
      },
      "source": [
        "## 2.3: Implement Evaluation Function (6 points)\n",
        "\n",
        "Create a function that calculates accuracy, precision, recall, and F1-score given predicted and true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsO4Rwz6RHqH"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true: List[int], y_pred: List[int]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with accuracy, precision, recall, f1_score\n",
        "    \"\"\"\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    p, r, f, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"binary\", zero_division=0\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": p,\n",
        "        \"recall\": r,\n",
        "        \"f1\": f\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEpUfSf2RHqH"
      },
      "source": [
        "## 2.4: 10-Fold Cross-Validation for Language Identification (8 points)\n",
        "\n",
        "Implement 10-fold cross-validation to evaluate your character-based n-gram models. In each fold, split the data, train separate models for each language and n-gram order, make predictions, and evaluate performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqLvr7twRHqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4edc37b-09e4-4455-93fa-b8b03bbcd84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared:\n",
            "  Total sentences: 3350\n",
            "  Language 1 (label 0): 916 sentences\n",
            "  Language 2 (label 1): 2434 sentences\n",
            "\n",
            "\n",
            "****************************************\n",
            "Fold 1-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 798 sentences\n",
            "  Lang2: 2217 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.964\n",
            "  3-gram Fold Accuracy: 0.973\n",
            "\n",
            "****************************************\n",
            "Fold 2-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 822 sentences\n",
            "  Lang2: 2193 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.973\n",
            "  3-gram Fold Accuracy: 0.994\n",
            "\n",
            "****************************************\n",
            "Fold 3-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 830 sentences\n",
            "  Lang2: 2185 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.982\n",
            "  3-gram Fold Accuracy: 0.988\n",
            "\n",
            "****************************************\n",
            "Fold 4-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 840 sentences\n",
            "  Lang2: 2175 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.982\n",
            "  3-gram Fold Accuracy: 0.988\n",
            "\n",
            "****************************************\n",
            "Fold 5-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 819 sentences\n",
            "  Lang2: 2196 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.976\n",
            "  3-gram Fold Accuracy: 0.985\n",
            "\n",
            "****************************************\n",
            "Fold 6-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 832 sentences\n",
            "  Lang2: 2183 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.973\n",
            "  3-gram Fold Accuracy: 0.988\n",
            "\n",
            "****************************************\n",
            "Fold 7-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 831 sentences\n",
            "  Lang2: 2184 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.976\n",
            "  3-gram Fold Accuracy: 0.991\n",
            "\n",
            "****************************************\n",
            "Fold 8-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 812 sentences\n",
            "  Lang2: 2203 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.970\n",
            "  3-gram Fold Accuracy: 0.991\n",
            "\n",
            "****************************************\n",
            "Fold 9-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 822 sentences\n",
            "  Lang2: 2193 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.976\n",
            "  3-gram Fold Accuracy: 0.991\n",
            "\n",
            "****************************************\n",
            "Fold 10-10\n",
            "****************************************\n",
            "  Train size: 3015\n",
            "  Lang1: 838 sentences\n",
            "  Lang2: 2177 sentences\n",
            "  Test size: 335\n",
            "  2-gram Fold Accuracy: 0.970\n",
            "  3-gram Fold Accuracy: 0.985\n",
            "\n",
            "***********************************\n",
            "Cross-validation completed!\n",
            "***********************************\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Prepare dataset: combine sentence STRINGS from both languages with labels\n",
        "X = lang1_sentences + lang2_sentences\n",
        "y = [0] * len(lang1_sentences) + [1] * len(lang2_sentences)\n",
        "\n",
        "\n",
        "print(f\"Dataset prepared:\")\n",
        "print(f\"  Total sentences: {len(X)}\")\n",
        "print(f\"  Language 1 (label 0): {sum(1 for label in y if label == 0)} sentences\")\n",
        "print(f\"  Language 2 (label 1): {sum(1 for label in y if label == 1)} sentences\")\n",
        "print()\n",
        "\n",
        "# Initialize 10-fold cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Store results for each fold\n",
        "results_2gram = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "results_3gram = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "\n",
        "\n",
        "for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(X), 1):\n",
        "    print(f\"\\n{'*'*40}\")\n",
        "    print(f\"Fold {fold_idx}-10\")\n",
        "    print(f\"{'*'*40}\")\n",
        "\n",
        "    X_train =[X[i] for i in train_idx]\n",
        "    y_train =[y[i] for i in train_idx]\n",
        "    X_test =[X[i] for i in test_idx]\n",
        "    y_test =[y[i] for i in test_idx]\n",
        "\n",
        "    train_lang1 = []\n",
        "    train_lang2 = []\n",
        "    for sent, label in zip(X_train, y_train):\n",
        "        if label == 0:\n",
        "            train_lang1.append(sent)\n",
        "        else:\n",
        "            train_lang2.append(sent)\n",
        "\n",
        "    print(f\"  Train size: {len(X_train)}\")\n",
        "    print(f\"  Lang1: {len(train_lang1)} sentences\")\n",
        "    print(f\"  Lang2: {len(train_lang2)} sentences\")\n",
        "    print(f\"  Test size: {len(X_test)}\")\n",
        "\n",
        "    model2_l1 = CharNgramLanguageModel(n=2)\n",
        "    model2_l2 = CharNgramLanguageModel(n=2)\n",
        "    model3_l1 = CharNgramLanguageModel(n=3)\n",
        "    model3_l2 = CharNgramLanguageModel(n=3)\n",
        "\n",
        "    model2_l1.train(train_lang1)\n",
        "    model2_l2.train(train_lang2)\n",
        "    model3_l1.train(train_lang1)\n",
        "    model3_l2.train(train_lang2)\n",
        "\n",
        "   # 4) make predictions on test set\n",
        "    y_pred_2 = []\n",
        "    y_pred_3 = []\n",
        "    for sent in X_test:\n",
        "        pred2 = identify_language(sent, model2_l1, model2_l2)\n",
        "        pred3 = identify_language(sent, model3_l1, model3_l2)\n",
        "        y_pred_2.append(pred2)\n",
        "        y_pred_3.append(pred3)\n",
        "\n",
        "    # 5) calculate metrics for this fold\n",
        "    metrics2 = calculate_metrics(y_test, y_pred_2)\n",
        "    metrics3 = calculate_metrics(y_test, y_pred_3)\n",
        "\n",
        "    # 6) store metrics into the dicts\n",
        "    for key in results_2gram:\n",
        "        results_2gram[key].append(metrics2[key])\n",
        "        results_3gram[key].append(metrics3[key])\n",
        "\n",
        "    # print fold metrics\n",
        "    print(f\"  2-gram Fold Accuracy: {metrics2['accuracy']:.3f}\")\n",
        "    print(f\"  3-gram Fold Accuracy: {metrics3['accuracy']:.3f}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"*\"*35)\n",
        "print(\"Cross-validation completed!\")\n",
        "print(\"*\"*35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlXE_SfFRHqH"
      },
      "source": [
        "## 2.5: Display Results (12)\n",
        "\n",
        "*Create a table showing for each model:*\n",
        "Mean accuracy, precision, recall, F1 (with std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyBVJGxFRHqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea21f7ac-7dc2-41f9-fe09-2bae059f7d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**************** RESULTS **************** \n",
            "    Model  Accuracy  Precision    Recall  F1-score\n",
            "0  2-gram  0.974328   0.968227  0.997129  0.982443\n",
            "1  3-gram  0.987463   0.984813  0.997936  0.991316\n"
          ]
        }
      ],
      "source": [
        "# make averages for each metric (just taking the mean of the 10 folds)\n",
        "avg_acc_2  = np.mean(results_2gram['accuracy'])\n",
        "avg_prec_2 = np.mean(results_2gram['precision'])\n",
        "avg_rec_2  = np.mean(results_2gram['recall'])\n",
        "avg_f1_2   = np.mean(results_2gram['f1'])\n",
        "\n",
        "avg_acc_3  = np.mean(results_3gram['accuracy'])\n",
        "avg_prec_3 = np.mean(results_3gram['precision'])\n",
        "avg_rec_3  = np.mean(results_3gram['recall'])\n",
        "avg_f1_3   = np.mean(results_3gram['f1'])\n",
        "\n",
        "# put everything into a small table\n",
        "summary_table = pd.DataFrame({\n",
        "    \"Model\": [\"2-gram\", \"3-gram\"],\n",
        "    \"Accuracy\":  [avg_acc_2,  avg_acc_3],\n",
        "    \"Precision\": [avg_prec_2, avg_prec_3],\n",
        "    \"Recall\":    [avg_rec_2, avg_rec_3],\n",
        "    \"F1-score\":  [avg_f1_2,  avg_f1_3]\n",
        "})\n",
        "\n",
        "print(\"\\n**************** RESULTS **************** \")\n",
        "print(summary_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7XedIvGRHqH"
      },
      "source": [
        "**Question 2.1:** Which of your trained models performed best on the validation data, and why? (3-4 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz1s_WlARHqH"
      },
      "source": [
        "**Hocam,As we can see from the results 3-gram model performed higher accuracy,precision,recal,F1-score. Thats really normal because 3 grams captures more contextual information than 2 grams.in short 3-grams has more accurate language predictions,because extra char helps the model distinguish better.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckv543M4RHqH"
      },
      "source": [
        "**Question 2.2:** Were the results consistent across different folds of cross-validation? (2-3 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkbHF5HbRHqH"
      },
      "source": [
        "**Yes it was.The results are consistent from 10 folds. results are pretty close each other.Which means the model isnt sensitive to how the folds are split which is reall good for us.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk7uadeZRHqH"
      },
      "source": [
        "## 2.6: Out-of-Vocabulary Testing (12 pts)\n",
        "\n",
        "Test your models with **five** sentences containing characters or character combinations not common in your training corpus. For character n-grams, this might include unusual letter combinations, foreign words, or made-up words that still follow language patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj0QEDnARHqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce0960b-2ce2-4a6f-eed1-c1c4008d46b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********** OOV TESTING **********\n",
            "\n",
            "Sentence: I really love doing assignments in midterm weeks\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -150.80\n",
            "    Turkish log-prob: -199.24\n",
            "    Prediction: English\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -128.92\n",
            "    Turkish log-prob: -192.16\n",
            "    Prediction: English\n",
            "\n",
            "Sentence: today I uyumadım to study midterms\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -130.95\n",
            "    Turkish log-prob: -121.29\n",
            "    Prediction: Turkish\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -121.84\n",
            "    Turkish log-prob: -125.91\n",
            "    Prediction: English\n",
            "\n",
            "Sentence: bugün sınıfta eartquake oldu\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -115.89\n",
            "    Turkish log-prob: -98.78\n",
            "    Prediction: Turkish\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -115.45\n",
            "    Turkish log-prob: -100.78\n",
            "    Prediction: Turkish\n",
            "\n",
            "Sentence: Artık havalar cold olmaya başladı.I think buna hiç necessary\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -209.85\n",
            "    Turkish log-prob: -177.23\n",
            "    Prediction: Turkish\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -214.90\n",
            "    Turkish log-prob: -160.31\n",
            "    Prediction: Turkish\n",
            "\n",
            "Sentence: asdf qwerty zxcv this is nonsense\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -123.71\n",
            "    Turkish log-prob: -156.43\n",
            "    Prediction: English\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -116.74\n",
            "    Turkish log-prob: -135.08\n",
            "    Prediction: English\n",
            "\n",
            "Sentence: sınif türküçe karışıg sentence 123\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -135.88\n",
            "    Turkish log-prob: -109.65\n",
            "    Prediction: Turkish\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -133.56\n",
            "    Turkish log-prob: -120.19\n",
            "    Prediction: Turkish\n",
            "\n",
            "Sentence: Yeter Alice\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -37.39\n",
            "    Turkish log-prob: -37.57\n",
            "    Prediction: English\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -33.22\n",
            "    Turkish log-prob: -40.82\n",
            "    Prediction: English\n",
            "\n",
            "Sentence: Come Berkay\n",
            "  --- 2-gram ---\n",
            "    English log-prob: -38.92\n",
            "    Turkish log-prob: -39.53\n",
            "    Prediction: English\n",
            "  --- 3-gram ---\n",
            "    English log-prob: -41.87\n",
            "    Turkish log-prob: -43.16\n",
            "    Prediction: English\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n********** OOV TESTING **********\\n\")\n",
        "\n",
        "# just some random sentences that are not from training data\n",
        "oov_sentences = [\n",
        "    \"I really love doing assignments in midterm weeks\",\n",
        "    \"today I uyumadım to study midterms\",\n",
        "    \"bugün sınıfta eartquake oldu\",\n",
        "    \"Artık havalar cold olmaya başladı.I think buna hiç necessary\",\n",
        "    \"asdf qwerty zxcv this is nonsense\",\n",
        "    \"sınif türküçe karışıg sentence 123\",\n",
        "    \"Yeter Alice\",\n",
        "    \"Come Berkay\"\n",
        "]\n",
        "\n",
        "for s in oov_sentences:\n",
        "    # 2-gram predictions\n",
        "    log_en_2 = math.log(en2.get_probability(s))\n",
        "    log_tr_2 = math.log(tr2.get_probability(s))\n",
        "    pred2 = \"English\" if log_en_2 > log_tr_2 else \"Turkish\"\n",
        "\n",
        "    # 3-gram predictions\n",
        "    log_en_3 = math.log(en3.get_probability(s))\n",
        "    log_tr_3 = math.log(tr3.get_probability(s))\n",
        "    pred3 = \"English\" if log_en_3 > log_tr_3 else \"Turkish\"\n",
        "\n",
        "    print(f\"Sentence: {s}\")\n",
        "    print(f\"  --- 2-gram ---\")\n",
        "    print(f\"    English log-prob: {log_en_2:.2f}\")\n",
        "    print(f\"    Turkish log-prob: {log_tr_2:.2f}\")\n",
        "    print(f\"    Prediction: {pred2}\")\n",
        "\n",
        "    print(f\"  --- 3-gram ---\")\n",
        "    print(f\"    English log-prob: {log_en_3:.2f}\")\n",
        "    print(f\"    Turkish log-prob: {log_tr_3:.2f}\")\n",
        "    print(f\"    Prediction: {pred3}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqrkgUOARHqH"
      },
      "source": [
        "**Question 2.3:** How well did your models handle out-of-vocabulary (OOV) samples? (2-3 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taFkBF3JRHqH"
      },
      "source": [
        "**Actually It was good.I just made up sentences,in most cases 2 and 3 gram predicted correctly.As we discussed before 3 gram did a better job because it has more context to helps it deal with unsual or unseen sequences.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz19fjohRHqH"
      },
      "source": [
        "---\n",
        "\n",
        "# Task 3: Statistical Analysis (20 points)\n",
        "\n",
        "**Baseline (10 pts):** Statistical significance testing and comparison.  \n",
        "**Creativity (10 pts):** Advanced analysis (confusion matrices, error analysis, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peCDCXqqRHqO"
      },
      "source": [
        "## 3.1: Statistical Significance Testing (10 points)\n",
        "\n",
        "Use paired t-test to compare models. p-value < 0.05 indicates statistically significant difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNrEt4s5RHqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a45e88-cb3a-4f77-fa20-7f6961164d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********** Paired t-test (2-gram vs 3-gram) **********\n",
            "\n",
            "Accuracy:\n",
            "  mean 2-gram = 0.9743\n",
            "  mean 3-gram = 0.9875\n",
            "  p-value     = 0.000034\n",
            "\n",
            "Precision:\n",
            "  mean 2-gram = 0.9682\n",
            "  mean 3-gram = 0.9848\n",
            "  p-value     = 0.000121\n",
            "\n",
            "Recall:\n",
            "  mean 2-gram = 0.9971\n",
            "  mean 3-gram = 0.9979\n",
            "  p-value     = 0.340270\n",
            "\n",
            "F1-score:\n",
            "  mean 2-gram = 0.9824\n",
            "  mean 3-gram = 0.9913\n",
            "  p-value     = 0.000040\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n********** Paired t-test (2-gram vs 3-gram) **********\\n\")\n",
        "\n",
        "# get fold arrays\n",
        "acc_2,  acc_3  = np.array(results_2gram['accuracy']),  np.array(results_3gram['accuracy'])\n",
        "prec_2, prec_3 = np.array(results_2gram['precision']), np.array(results_3gram['precision'])\n",
        "rec_2,  rec_3  = np.array(results_2gram['recall']),    np.array(results_3gram['recall'])\n",
        "f1_2,   f1_3   = np.array(results_2gram['f1']),        np.array(results_3gram['f1'])\n",
        "\n",
        "def test_and_print(name, arr2, arr3):\n",
        "    t, p = ttest_rel(arr2, arr3)\n",
        "\n",
        "\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  mean 2-gram = {arr2.mean():.4f}\")\n",
        "    print(f\"  mean 3-gram = {arr3.mean():.4f}\")\n",
        "    print(f\"  p-value     = {p:.6f}\")\n",
        "\n",
        "\n",
        "test_and_print(\"Accuracy\",  acc_2,  acc_3)\n",
        "test_and_print(\"\\nPrecision\", prec_2, prec_3)\n",
        "test_and_print(\"\\nRecall\",    rec_2,  rec_3)\n",
        "test_and_print(\"\\nF1-score\",  f1_2,   f1_3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20soxRd6RHqO"
      },
      "source": [
        "**Question 3.1:** Are the performance differences statistically significant? Explain what 'statistical significance' means in this context. (2-3 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KiLvz4RHqP"
      },
      "source": [
        "**Yes,Performance differences statistically significant for accuracy,precision,and F1-score Because p value smaller than 0.05. this is the proof of the improvement of the model 3 gram is unlikely to be due to random chance and is istead real reliable differnce.In short, Yes we can say that 3 gram model performs better.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lms2PaRRHqP"
      },
      "source": [
        "## 3.2: Advanced Analysis (10 points)\n",
        "\n",
        "Perform deeper analysis such as per-language performance, misclassification patterns, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvOfyE8ORHqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02707ede-959a-45db-b794-fb90184754c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********** 3.2 Advanced Analysis (2-gram vs 3-gram) **********\n",
            "\n",
            "Overall accuracy:\n",
            "  2-gram: 0.975\n",
            "  3-gram: 0.989\n",
            "\n",
            "Per-language accuracy:\n",
            "  2-gram  English: 0.914 | Turkish: 0.998\n",
            "  3-gram  English: 0.963 | Turkish: 0.999\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total misclassified sentences by 3-gram model: 37\n",
            "Some misclassified examples (up to 10):\n",
            "  TRUE=English, PRED=Turkish: 'Down the Rabbit-Hole Alice was beginning to get very tired of sitting by her sis...'\n",
            "  TRUE=English, PRED=Turkish: 'I shall be late!” (when she thought it over afterwards, it occurred to her that ...'\n",
            "  TRUE=English, PRED=Turkish: 'Let me see: that would be four thousand miles down, I think—” (for, you see, Ali...'\n",
            "  TRUE=English, PRED=Turkish: 'There seemed to be no use in waiting by the little door, so she went back to the...'\n",
            "  TRUE=English, PRED=Turkish: '“No, I’ll look first,” she said, “and see whether it’s marked ‘_poison_’ or not”...'\n",
            "  TRUE=English, PRED=Turkish: '“Come, there’s no use in crying like that!” said Alice to herself, rather sharpl...'\n",
            "  TRUE=English, PRED=Turkish: '(Alice had been to the seaside once in her life, and had come to the general con...'\n",
            "  TRUE=English, PRED=Turkish: 'She is such a dear quiet thing,” Alice went on, half to herself, as she swam laz...'\n",
            "  TRUE=English, PRED=Turkish: 'Do come back again, and we won’t talk about cats or dogs either, if you don’t li...'\n",
            "  TRUE=English, PRED=Turkish: 'However, when they had been running half an hour or so, and were quite dry again...'\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"\\n********** 3.2 Advanced Analysis (2-gram vs 3-gram) **********\\n\")\n",
        "\n",
        "# 1) get predictions of both models on the whole dataset\n",
        "y_pred_2gram = []\n",
        "y_pred_3gram = []\n",
        "\n",
        "for sent in X:\n",
        "    y_pred_2gram.append(identify_language(sent, en2, tr2))  # 0 = English, 1 = Turkish\n",
        "    y_pred_3gram.append(identify_language(sent, en3, tr3))\n",
        "\n",
        "# overall accuracies\n",
        "overall_acc_2 = accuracy_score(y, y_pred_2gram)\n",
        "overall_acc_3 = accuracy_score(y, y_pred_3gram)\n",
        "\n",
        "print(\"Overall accuracy:\")\n",
        "print(f\"  2-gram: {overall_acc_2:.3f}\")\n",
        "print(f\"  3-gram: {overall_acc_3:.3f}\")\n",
        "\n",
        "\n",
        "# 2) per-language accuracy for both models\n",
        "def per_language_acc(y_true, y_pred):\n",
        "    correct_en = correct_tr = 0\n",
        "    total_en = total_tr = 0\n",
        "\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        if t == 0:          # English\n",
        "            total_en += 1\n",
        "            if p == 0:\n",
        "                correct_en += 1\n",
        "        else:               # Turkish\n",
        "            total_tr += 1\n",
        "            if p == 1:\n",
        "                correct_tr += 1\n",
        "\n",
        "    acc_en = correct_en / total_en\n",
        "    acc_tr = correct_tr / total_tr\n",
        "    return acc_en, acc_tr\n",
        "\n",
        "acc_en_2, acc_tr_2 = per_language_acc(y, y_pred_2gram)\n",
        "acc_en_3, acc_tr_3 = per_language_acc(y, y_pred_3gram)\n",
        "\n",
        "print(\"\\nPer-language accuracy:\")\n",
        "print(f\"  2-gram  English: {acc_en_2:.3f} | Turkish: {acc_tr_2:.3f}\")\n",
        "print(f\"  3-gram  English: {acc_en_3:.3f} | Turkish: {acc_tr_3:.3f}\")\n",
        "\n",
        "\n",
        "# 3) PLOTS\n",
        "# 3a) overall accuracy bar plot\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.bar([\"2-gram\", \"3-gram\"], [overall_acc_2, overall_acc_3])\n",
        "plt.ylim(0.9, 1.01)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Overall Accuracy (2-gram vs 3-gram)\")\n",
        "plt.show()\n",
        "\n",
        "# 3b) per language accuracy grouped bar plot\n",
        "labels = [\"English\", \"Turkish\"]\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(x - width/2, [acc_en_2, acc_tr_2], width, label=\"2-gram\")\n",
        "plt.bar(x + width/2, [acc_en_3, acc_tr_3], width, label=\"3-gram\")\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0.9, 1.01)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Per-Language Accuracy (2-gram vs 3-gram)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 4) misclassified sentences\n",
        "misclassified_3 = []\n",
        "for sent, true_label, pred_label in zip(X, y, y_pred_3gram):\n",
        "    if true_label != pred_label:\n",
        "        misclassified_3.append((sent, true_label, pred_label))\n",
        "\n",
        "print(\"\\nTotal misclassified sentences by 3-gram model:\", len(misclassified_3))\n",
        "print(\"Some misclassified examples (up to 10):\")\n",
        "for sent, true_l, pred_l in misclassified_3[:10]:\n",
        "    lang_true = \"English\" if true_l == 0 else \"Turkish\"\n",
        "    lang_pred = \"English\" if pred_l == 0 else \"Turkish\"\n",
        "    print(f\"  TRUE={lang_true}, PRED={lang_pred}: '{sent[:80]}...'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQxhIhmMRHqP"
      },
      "source": [
        "**Question 3.2:** What interesting patterns or insights did you discover from your results? (4-5 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tj2BkoiRHqP"
      },
      "source": [
        "**I can definetely say that 3 gram model did a great job unexpectedly that much.Another thing is 2 and 3 gram model has really similar accuracy on turkish, this is also interesting. Another thing is as you can see from the explamle sentence that provided \"Yeter Alice\" the prediction is not clear,but as you can see from \"Come Berkay\", this has also not clear but has better prediciton from previous one.So The reason behind it should be a due to the language difference effect it .**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLhYIeKiG01-"
      },
      "source": [
        "# Convert Your Colab Notebook to PDF\n",
        "\n",
        "### Step 1: Download Your Notebook\n",
        "- Go to **File → Download → Download .ipynb**\n",
        "- Save the file to your computer\n",
        "\n",
        "### Step 2: Upload to Colab\n",
        "- Click the **📁 folder icon** on the left sidebar\n",
        "- Click the **upload button**\n",
        "- Select your downloaded .ipynb file\n",
        "\n",
        "### Step 3: Run the Code Below\n",
        "- **Uncomment the cell below** and run the cell\n",
        "- This will take about 1-2 minutes to install required packages\n",
        "- When prompted, type your notebook name (e.g.`gs_000000_as2.ipynb`) and press Enter\n",
        "\n",
        "### The PDF will be automatically downloaded to your computer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDPvhmqPMCSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "98cda121-6d37-4bcb-e4eb-80118766135d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PDF converter... please wait...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Enter your notebook name: By_2385722\n",
            "\n",
            "✓ Found By_2385722.ipynb\n",
            "Converting to PDF... this may take 1-2 minutes...\n",
            "\n",
            "[NbConvertApp] Converting notebook /content/By_2385722.ipynb to pdf\n",
            "[NbConvertApp] Support files will be in By_2385722_files/\n",
            "[NbConvertApp] Making directory ./By_2385722_files\n",
            "[NbConvertApp] Writing 121724 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 156355 bytes to /content/By_2385722.pdf\n",
            "✓ SUCCESS! Downloading your PDF now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e9bb4213-b544-4362-96cf-20a25485979e\", \"By_2385722.pdf\", 156355)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Done! Check your downloads folder.\n"
          ]
        }
      ],
      "source": [
        " # Install required packages (this takes about 30 seconds)\n",
        " print(\"Installing PDF converter... please wait...\")\n",
        " !apt-get update -qq\n",
        " !apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic pandoc > /dev/null 2>&1\n",
        " !pip install -q nbconvert\n",
        "\n",
        " print(\"\\n\" + \"=\"*50)\n",
        "\n",
        " # Get notebook name from user\n",
        " notebook_name = input(\"\\nEnter your notebook name: \")\n",
        "\n",
        " # Add .ipynb if missing\n",
        " if not notebook_name.endswith('.ipynb'):\n",
        "     notebook_name += '.ipynb'\n",
        "\n",
        " import os\n",
        " notebook_path = f'/content/{notebook_name}'\n",
        "\n",
        " # Check if file exists\n",
        " if not os.path.exists(notebook_path):\n",
        "     print(f\"\\n⚠ Error: '{notebook_name}' not found in /content/\")\n",
        "     print(\"\\nMake sure you uploaded the file using the folder icon (📁) on the left!\")\n",
        " else:\n",
        "     print(f\"\\n✓ Found {notebook_name}\")\n",
        "     print(\"Converting to PDF... this may take 1-2 minutes...\\n\")\n",
        "     # Convert the notebook to PDF\n",
        "     !jupyter nbconvert --to pdf \"{notebook_path}\"\n",
        "\n",
        "     # Download the PDF\n",
        "     from google.colab import files\n",
        "     pdf_name = notebook_name.replace('.ipynb', '.pdf')\n",
        "     pdf_path = f'/content/{pdf_name}'\n",
        "\n",
        "     if os.path.exists(pdf_path):\n",
        "         print(\"✓ SUCCESS! Downloading your PDF now...\")\n",
        "         files.download(pdf_path)\n",
        "         print(\"\\n✓ Done! Check your downloads folder.\")\n",
        "     else:\n",
        "         print(\"⚠ Error: Could not create PDF\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}